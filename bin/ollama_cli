#!/usr/bin/env ruby

require 'ollama'
include Ollama
include Ollama::Utils::FileArgument
require 'tins'
include Tins::GO
require 'json'

def usage
  puts <<~EOT
    Usage: #{File.basename($0)} [OPTIONS]

      -u URL         the ollama base url, OLLAMA_URL
      -m MODEL       the ollama model to chat with, OLLAMA_MODEL
      -M OPTIONS     the ollama model options to use, OLLAMA_MODEL_OPTIONS
      -s SYSTEM      the system prompt to use as a file, OLLAMA_SYSTEM
      -p PROMPT      the user prompt to use as a file, OLLAMA_PROMPT
                     if it contains %{stdin} it is substituted by stdin input
      -P VARIABLE    sets prompt var %{foo} to "bar" if VARIABLE is foo=bar
      -H HANDLER     the handler to use for the response, defaults to Print
      -S             use streaming for generation
      -h             this help

  EOT
  exit 0
end

opts = go 'u:m:M:s:p:P:H:Sh', defaults: { ?H => 'Print', ?M => '{}' }

opts[?h] and usage

base_url = opts[?u] || ENV['OLLAMA_URL'] || 'http://%s' % ENV.fetch('OLLAMA_HOST')
model    = opts[?m] || ENV.fetch('OLLAMA_MODEL', 'llama3.1')
options  = Ollama::Options.from_hash(JSON(
  get_file_argument(opts[?M], default: ENV['OLLAMA_MODEL_OPTIONS'])
))
system   = get_file_argument(opts[?s], default: ENV['OLLAMA_SYSTEM'])
prompt   = get_file_argument(opts[?p], default: ENV['OLLAMA_PROMPT'])

if prompt.nil?
  prompt = STDIN.read
else
  vars = prompt.scan(/%\{([^}]+)\}/).inject([], &:concat).uniq.map(&:to_sym)
  stdin = (STDIN.read if vars.include?(:stdin)).to_s
  values = opts[?P].to_a.inject({ stdin: }) { |h, pair|
    n, v = pair.split(?=, 2)
    h.merge(n.to_sym => v)
  }
  prompt = prompt % values
end

if ENV['DEBUG'].to_i == 1
  puts <<~EOT
    base_url = #{base_url.inspect}
    model    = #{model.inspect}
    system   = #{system.inspect}
    prompt   = #{prompt.inspect}
    options  = #{options.to_json}
  EOT
end

Client.new(base_url:, read_timeout: 120).generate(
  model:,
  system:,
  prompt:,
  options:,
  stream: !!opts[?S],
  &Object.const_get(opts[?H])
)
