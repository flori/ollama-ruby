#!/usr/bin/env ruby

require 'ollama'
include Ollama
require 'term/ansicolor'
include Term::ANSIColor
require 'tins'
require 'tins/xt/full'
require 'tins/xt/hash_union'
include Tins::GO
require 'reline'
require 'reverse_markdown'
require 'complex_config'
require 'fileutils'
require 'uri'
require 'nokogiri'
require 'rss'
require 'pdf/reader'
require 'csv'
require 'xdg'

class OllamaChatConfig
  include ComplexConfig
  include FileUtils

  DEFAULT_CONFIG = <<~EOT
    ---
    url: <%= ENV['OLLAMA_URL'] || 'http://%s' % ENV.fetch('OLLAMA_HOST') %>
    proxy: null # http://localhost:8080
    model:
      name: <%= ENV.fetch('OLLAMA_CHAT_MODEL', 'llama3.1') %>
      options:
        num_ctx: 8192
    prompts:
      system: <%= ENV.fetch('OLLAMA_CHAT_SYSTEM', 'null') %>
      embed: "This source was now embedded: %{source}"
      summarize: |
        Generate an abstract summary of the content in this document using
        %{words} words:

        %{source_content}
      web: |
        Answer the the query %{query} using these sources and summaries:

        %{results}
    voice:
      enabled: false
      default: Samantha
      list: <%= `say -v ?`.lines.map { _1[/^(.+?)\s+[a-z]{2}_[a-zA-Z0-9]{2,}/, 1] }.uniq.sort.to_s.force_encoding('ASCII-8BIT') %>
    markdown: true
    stream: true
    embedding:
      enabled: true
      model:
        name: mxbai-embed-large
        options: {}
        # Retrieval prompt template:
        prompt: 'Represent this sentence for searching relevant passages: %s'
      collection: <%= ENV['OLLAMA_CHAT_COLLECTION'] %>
      found_texts_size: 4096
      found_texts_count: null
      splitter:
        name: RecursiveCharacter
        chunk_size: 1024
    cache: Ollama::Documents::Cache::RedisBackedMemoryCache
    redis:
      documents:
        url: <%= ENV.fetch('REDIS_URL', 'null') %>
      expiring:
        url: <%= ENV.fetch('REDIS_EXPIRING_URL', 'null') %>
        ex: 86400
    debug: <%= ENV['OLLAMA_CHAT_DEBUG'].to_i == 1 ? true : false %>
    ssl_no_verify: []
    copy: pbcopy
  EOT

  def initialize(filename = nil)
    @filename = filename || default_path
    @config = Provider.config(@filename, '‚öôÔ∏è')
    retried = false
  rescue ConfigurationFileMissing
    if @filename == default_path && !retried
      retried = true
      mkdir_p File.dirname(default_path)
      File.secure_write(default_path, DEFAULT_CONFIG)
      retry
    else
      raise
    end
  end

  attr_reader :filename

  attr_reader :config

  def default_path
    config_dir_path + 'config.yml'
  end

  def config_dir_path
    XDG.new.config_home + 'ollama_chat'
  end
end

class FollowChat
  include Ollama::Handlers::Concern
  include Term::ANSIColor

  def initialize(messages:, markdown: false, voice: nil, output: $stdout)
    super(output:)
    @output.sync = true
    @markdown = markdown
    @say = voice ? Handlers::Say.new(voice:) : NOP
    @messages = messages
    @user     = nil
  end

  def call(response)
    $config.debug and jj response
    if response&.message&.role == 'assistant'
      if @messages.last.role != 'assistant'
        @messages << Message.new(role: 'assistant', content: '')
        @user = message_type(@messages.last.images) + " " +
          bold { color(111) { 'assistant:' } }
        puts @user unless @markdown
      end
      content = response.message&.content
      @messages.last.content << content
      if @markdown and content = @messages.last.content.full?
        markdown_content = Utils::ANSIMarkdown.parse(content)
        @output.print clear_screen, move_home, @user, ?\n, markdown_content
      else
        @output.print content
      end
      @say.call(response)
    end
    if response.done
      @output.puts "", eval_stats(response)
    end
    self
  end

  def eval_stats(response)
    eval_duration = response.eval_duration / 1e9
    prompt_eval_duration = response.prompt_eval_duration / 1e9
    stats_text = {
      eval_duration:        Tins::Duration.new(eval_duration),
      eval_count:           response.eval_count.to_i,
      eval_rate:            bold { "%.2f c/s" % (response.eval_count.to_i / eval_duration) } + color(111),
      prompt_eval_duration: Tins::Duration.new(prompt_eval_duration),
      prompt_eval_count:    response.prompt_eval_count.to_i,
      prompt_eval_rate:     bold { "%.2f c/s" % (response.prompt_eval_count.to_i / prompt_eval_duration) } + color(111),
      total_duration:       Tins::Duration.new(response.total_duration / 1e9),
      load_duration:        Tins::Duration.new(response.load_duration / 1e9),
    }.map { _1 * '=' } * ' '
    'üìä ' + color(111) {
      Utils::Width.wrap(stats_text, percentage: 90).gsub(/(?<!\A)^/, '   ')
    }
  end
end

module CheckSwitch
  extend Tins::Concern

  included do
    alias_method :on?, :value
  end

  def off?
    !on?
  end

  def show
    puts @msg[value]
  end
end

class Switch
  def initialize(name, msg:, config: $config)
    @value = !!config.send("#{name}?")
    @msg   = msg
  end

  attr_reader :value

  def set(value, show: false)
    @value = !!value
    show && self.show
  end

  def toggle(show: true)
    @value = !@value
    show && self.show
  end

  include CheckSwitch
end

class CombinedSwitch
  def initialize(value:, msg:)
    @value = value
    @msg   = msg
  end

  def value
    @value.()
  end

  include CheckSwitch
end

def setup_switches
  $markdown = Switch.new(
    :markdown,
    msg: {
      true  => "Using #{italic{'ANSI'}} markdown to output content.",
      false => "Using plaintext for outputting content.",
    }
  )

  $stream = Switch.new(
    :stream,
    msg: {
      true  => "Streaming enabled.",
      false => "Streaming disabled.",
    }
  )

  $voice = Switch.new(
    :stream,
    msg: {
      true  => "Voice output enabled.",
      false => "Voice output disabled.",
    },
    config: $config.voice
  )

  $embedding_enabled = Switch.new(
    :embedding_enabled,
    msg: {
      true  => "Embedding enabled.",
      false => "Embedding disabled.",
    }
  )

  $embedding_paused = Switch.new(
    :embedding_paused,
    msg: {
      true  => "Embedding paused.",
      false => "Embedding resumed.",
    }
  )

  $embedding = CombinedSwitch.new(
    value: -> { $embedding_enabled.on? && $embedding_paused.off? },
    msg: {
      true  => "Embedding is currently performed.",
      false => "Embedding is currently not performed.",
    }
  )
end

def search_web(query, n = nil)
  n = n.to_i
  n < 1 and n = 1
  query = URI.encode_uri_component(query)
  url = "https://www.duckduckgo.com/html/?q=#{query}"
  Ollama::Utils::Fetcher.get(url, debug: $config.debug) do |tmp|
    result = []
    doc = Nokogiri::HTML(tmp)
    doc.css('.results_links').each do |link|
      if n > 0
        url = link.css('.result__a').first&.[]('href')
        url.sub!(%r(\A/l/\?uddg=), '')
        url.sub!(%r(&rut=.*), '')
        url = URI.decode_uri_component(url)
        url = URI.parse(url)
        url.host =~ /duckduckgo\.com/ and next
        result << url
        n -= 1
      else
        break
      end
    end
    result
  end
end

def pull_model_unless_present(model, options, retried = false)
  ollama.show(name: model) { |response|
    puts "Model #{bold{model}} with architecture "\
      "#{response.model_info['general.architecture']} found."
    if system = response.system
      puts "Configured model system prompt is:\n#{italic { system }}"
      return system
    else
      return
    end
  }
rescue Errors::NotFoundError
  puts "Model #{bold{model}} not found locally, attempting to pull it from remote now‚Ä¶"
  ollama.pull(name: model)
  if retried
    exit 1
  else
    retried = true
    retry
  end
rescue Errors::Error => e
  warn "Caught #{e.class} while pulling model: #{e} => Exiting."
  exit 1
end

def load_conversation(filename)
  unless File.exist?(filename)
    puts "File #{filename} doesn't exist. Choose another filename."
    return
  end
  File.open(filename, 'r') do |output|
    return JSON(output.read).map { Ollama::Message.from_hash(_1) }
  end
end

def save_conversation(filename, messages)
  if File.exist?(filename)
    puts "File #{filename} already exists. Choose another filename."
    return
  end
  File.open(filename, 'w') do |output|
    output.puts JSON(messages)
  end
end

def message_type(images)
  images.present? ? ?üì∏ : ?üì®
end

def list_conversation(messages, last = nil)
  last = (last || messages.size).clamp(0, messages.size)
  messages[-last..-1].to_a.each do |m|
    role_color = case m.role
                 when 'user' then 172
                 when 'assistant' then 111
                 when 'system' then 213
                 else 210
                 end
    content = m.content.full? { $markdown.on? ? Utils::ANSIMarkdown.parse(_1) : _1 }
    message_text = message_type(m.images) + " "
    message_text += bold { color(role_color) { m.role } }
    message_text += ":\n#{content}"
    m.images.full? { |images|
      message_text += "\nImages: " + italic { images.map(&:path) * ', ' }
    }
    puts message_text
  end
end

def reverse_markdown(html)
  ReverseMarkdown.convert(
    html,
    unknown_tags: :bypass,
    github_flavored: true,
    tag_border: ''
  )
end

def parse_rss(source_io)
  feed = RSS::Parser.parse(source_io, false, false)
  title = <<~EOT
    # #{feed&.channel&.title}

  EOT
  feed.items.inject(title) do |text, item|
    text << <<~EOT
      ## [#{item&.title}](#{item&.link})

      updated on #{item&.pubDate}

      #{reverse_markdown(item&.description)}

    EOT
  end
end

def parse_atom(source_io)
  feed = RSS::Parser.parse(source_io, false, false)
  title = <<~EOT
    # #{feed.title.content}

  EOT
  feed.items.inject(title) do |text, item|
    text << <<~EOT
      ## [#{item&.title&.content}](#{item&.link&.href})

      updated on #{item&.updated&.content}

      #{reverse_markdown(item&.content&.content)}

    EOT
  end
end

def parse_source(source_io)
  case source_io&.content_type
  when 'text/html'
    reverse_markdown(source_io.read)
  when 'text/xml'
    if source_io.readline =~ %r(^\s*<rss\s)
      source_io.rewind
      return parse_rss(source_io)
    end
    source_io.rewind
    source_io.read
  when 'text/csv'
    result = +''
    CSV.table(File.new(source_io), col_sep: ?,).each do |row|
      next if row.fields.select(&:present?).size == 0
      result << row.map { |pair|
        pair.compact.map { _1.to_s.strip } * ': ' if pair.last.present?
      }.select(&:present?).map { _1.prepend('  ') } * ?\n
      result << "\n\n"
    end
    result
  when 'application/rss+xml'
    parse_rss(source_io)
  when 'application/atom+xml'
    parse_atom(source_io)
  when 'application/json'
    source_io.read
  when 'application/pdf'
    reader = PDF::Reader.new(source_io)
    reader.pages.inject(+'') { |result, page| result << page.text }
  when %r(\Atext/), nil
    source_io.read
  else
    STDERR.puts "Cannot embed #{source_io&.content_type} document."
    return
  end
end

def embed_source(source_io, source)
  $embedding.on? or return parse_source(source_io)
  puts "Embedding #{italic { source_io&.content_type }} document #{source.to_s.inspect}."
  text = parse_source(source_io) or return
  text.downcase!
  splitter_config = $config.embedding.splitter
  inputs = nil
  case splitter_config.name
  when 'Character'
    splitter = Ollama::Documents::Splitters::Character.new(
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(text)
  when 'RecursiveCharacter'
    splitter = Ollama::Documents::Splitters::RecursiveCharacter.new(
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(text)
  when 'Semantic'
    splitter = Ollama::Documents::Splitters::Semantic.new(
      ollama:, model: $config.embedding.model.name,
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(
      text,
      breakpoint: splitter_config.breakpoint.to_sym,
      percentage: splitter_config.percentage?,
      percentile: splitter_config.percentile?,
    )
    inputs = splitter.split(text)
  end
  inputs or return
  source = source.to_s
  if source.start_with?(?!)
    source = Ollama::Utils::Width.truncate(
      source[1..-1].gsub(/\W+/, ?_),
      length: 10
    )
  end
  $documents.add(inputs, source: source)
end

def add_image(images, source_io, source)
  STDERR.puts "Adding #{source_io&.content_type} image #{source.to_s.inspect}."
  image = Image.for_io(source_io, path: source.to_s)
  (images << image).uniq!
end

def http_options(url)
  options = {}
  if ssl_no_verify = $config.ssl_no_verify?
    hostname = URI.parse(url).hostname
    options |= { ssl_verify_peer: !ssl_no_verify.include?(hostname) }
  end
  if proxy = $config.proxy?
    options |= { proxy: }
  end
  options
end

def fetch_source(source, &block)
  case source
  when %r(\A!(.*))
    command = $1
    Utils::Fetcher.execute(command) do |tmp|
      block.(tmp)
    end
  when %r(\Ahttps?://\S+)
    Utils::Fetcher.get(
      source,
      cache:        $cache,
      debug:        $config.debug,
      http_options: http_options(source)
    ) do |tmp|
      block.(tmp)
    end
  when %r(\Afile://(?:(?:[.-]|[[:alnum:]])*)(/\S*)|([~.]?/\S*))
    filename = $~.captures.compact.first
    filename = File.expand_path(filename)
    Utils::Fetcher.read(filename) do |tmp|
      block.(tmp)
    end
  else
    raise "invalid source"
  end
rescue => e
  STDERR.puts "Cannot fetch source #{source.to_s.inspect}: #{e}\n#{e.backtrace * ?\n}"
end

def import(source)
  puts "Now importing #{source.to_s.inspect}."
  fetch_source(source) do |source_io|
    content = parse_source(source_io)
    content.present? or return
    source_io.rewind
    content
  end
end

def summarize(source, words: nil)
  words = words.to_i
  words < 1 and words = 100
  puts "Now summarizing #{source.to_s.inspect}."
  source_content =
    fetch_source(source) do |source_io|
      content = parse_source(source_io)
      content.present? or return
      source_io.rewind
      content
    end
  $config.prompts.summarize % { source_content:, words: }
end

def embed(source)
  if $embedding.on?
    puts "Now embedding #{source.to_s.inspect}."
    fetch_source(source) do |source_io|
      content = parse_source(source_io)
      content.present? or return
      source_io.rewind
      embed_source(source_io, source)
      content
    end
    $config.prompts.embed % { source: }
  else
    puts "Embedding is off, so I will just give a small summary of this source."
    summarize(source)
  end
end

def parse_content(content, images)
  images.clear
  tags = Utils::Tags.new

  content.scan(%r([.~]?/\S+|https?://\S+|#\S+)).each do |source|
    case source
    when /\A#(\S+)/
      tags << $1
    else
      source = source.sub(/(["')]|\*+)\z/, '')
      fetch_source(source) do |source_io|
        case source_io&.content_type&.media_type
        when 'image'
          add_image(images, source_io, source)
        when 'text', 'application'
          embed_source(source_io, source)
        else
          STDERR.puts(
            "Cannot fetch #{source.to_s.inspect} with content type "\
            "#{source_io&.content_type.inspect}"
          )
        end
      end
    end
  end

  return content, (tags unless tags.empty?)
end

def choose_model(cli_model, default_model)
  models = ollama.tags.models.map(&:name).sort
  model = if cli_model == ''
            Ollama::Utils::Chooser.choose(models) || default_model
          else
            cli_model || default_model
          end
ensure
  puts green { "Connecting to #{model}@#{ollama.base_url} now‚Ä¶" }
end

def choose_collection(default_collection)
  collections = [ default_collection ] + $documents.collections
  collections = collections.compact.map(&:to_s).uniq.sort
  collections.unshift('[NEW]')
  collection = Ollama::Utils::Chooser.choose(collections) || default_collection
  if collection == '[NEW]'
      print "Enter name of the new collection: "
      collection = STDIN.gets.chomp
  end
  $documents.collection = collection
ensure
  puts "Changing to collection #{bold{collection}}."
  collection_stats
end

def collection_stats
  puts <<~EOT
    Collection
      Name: #{bold{$documents.collection}}
      Embedding model: #{bold{$embedding_model}}
      #Embeddings: #{$documents.size}
      Tags: #{$documents.tags}
  EOT
end

def configure_cache
  if $opts[?M]
    Ollama::Documents::MemoryCache
  else
    Object.const_get($config.cache)
  end
rescue => e
  STDERR.puts "Caught #{e.class}: #{e} => Falling back to MemoryCache."
  Ollama::Documents::MemoryCache
end

def show_system_prompt
  puts <<~EOT
    Configured system prompt is:
    #{Ollama::Utils::ANSIMarkdown.parse($system.to_s).gsub(/\n+\z/, '').full? || 'n/a'}
  EOT
end

def set_system_prompt(messages, system)
  $system = system
  messages.clear
  messages << Message.new(role: 'system', content: system)
end

def change_system_prompt(messages)
  prompts = $config.system_prompts.attribute_names.compact
  chosen  = Ollama::Utils::Chooser.choose(prompts)
  system  = if chosen
              $config.system_prompts.send(chosen)
            else
              default
            end
  set_system_prompt(messages, system)
end

def change_voice
  chosen  = Ollama::Utils::Chooser.choose($config.voice.list)
  $current_voice = chosen.full? || $config.voice.default
end

def info
  puts "Current model is #{bold{$model}}."
  collection_stats
  $embedding.show
  if $embedding.on?
    puts "Text splitter is #{bold{$config.embedding.splitter.name}}."
  end
  puts "Documents database cache is #{$documents.nil? ? 'n/a' : bold{$documents.cache.class}}"
  $markdown.show
  $stream.show
  if $voice.on?
    puts "Using voice #{bold{$current_voice}} to speak."
  end
  show_system_prompt
end

def clear_messages(messages)
  messages.delete_if { _1.role != 'system' }
end

def copy_to_clipboard(messages)
  if message = messages.last and message.role == 'assistant'
    copy = `which #{$config.copy}`.chomp
    if copy.present?
      IO.popen(copy, 'w') do |clipboard|
        clipboard.write(message.content)
      end
      STDOUT.puts "The last response has been copied to the system clipboard."
    else
      STDERR.puts "#{$config.copy.inspect} command not found in system's path!"
    end
  else
    STDERR.puts "No response available to copy to the system clipboard."
  end
end

def display_chat_help
  puts <<~EOT
    /copy                           to copy last response to clipboard
    /paste                          to paste content
    /markdown                       toggle markdown output
    /stream                         toggle stream output
    /voice( change)                 toggle voice output or change the voice
    /list [n]                       list the last n / all conversation exchanges
    /clear                          clear the whole conversation
    /clobber                        clear the conversation and collection
    /pop [n]                        pop the last n exchanges, defaults to 1
    /model                          change the model
    /system                         change system prompt (clears conversation)
    /regenerate                     the last answer message
    /collection clear [tag]|change  clear or show stats of current collection
    /import source                  import the source's content
    /summarize [n] source           summarize the source's content in n words
    /embedding                      toggle embedding paused or not
    /embed source                   embed the source's content
    /web [n] query                  query web search & return n or 1 results
    /save filename                  store conversation messages
    /load filename                  load conversation messages
    /quit                           to quit
    /help                           to view this help
  EOT
end

def usage
  puts <<~EOT
    #{File.basename($0)} [OPTIONS]

      -f CONFIG      config file to read
      -u URL         the ollama base url, OLLAMA_URL
      -m MODEL       the ollama model to chat with, OLLAMA_CHAT_MODEL
      -s SYSTEM      the system prompt to use as a file, OLLAMA_CHAT_SYSTEM
      -c CHAT        a saved chat conversation to load
      -C COLLECTION  name of the collection used in this conversation
      -D DOCUMENT    load document and add to embeddings collection (multiple)
      -M             use (empty) MemoryCache for this chat session
      -E             disable embeddings for this chat session
      -V             display the current version number and quit
      -h             this help

  EOT
  exit 0
end

def version
  puts "%s %s" % [ File.basename($0), Ollama::VERSION ]
  exit 0
end

def ollama
  $ollama
end

$opts = go 'f:u:m:s:c:C:D:MEVh'

config = OllamaChatConfig.new($opts[?f])
$config = config.config

setup_switches

$opts[?h] and usage
$opts[?V] and version

base_url = $opts[?u] || $config.url
$ollama      = Client.new(base_url:, debug: $config.debug)

$model       = choose_model($opts[?m], $config.model.name)
options      = Options[$config.model.options]
model_system = pull_model_unless_present($model, options)
messages     = []
$embedding_enabled.set($config.embedding.enabled && !$opts[?E])

if $opts[?c]
  messages.concat load_conversation($opts[?c])
else
  default = $config.system_prompts.default? || model_system
  if $opts[?s] == ??
    change_system_prompt(messages)
  else
    system = Ollama::Utils::FileArgument.get_file_argument($opts[?s], default:)
    system.present? and set_system_prompt(messages, system)
  end
end

if $embedding.on?
  $embedding_model         = $config.embedding.model.name
  embedding_model_options = Options[$config.embedding.model.options]
  pull_model_unless_present($embedding_model, embedding_model_options)
  collection = $opts[?C] || $config.embedding.collection
  $documents = Documents.new(
    ollama:,
    model:         $embedding_model,
    model_options: $config.embedding.model.options,
    collection:,
    cache:         configure_cache,
    redis_url:     $config.redis.documents.url?,
    debug:         ENV['DEBUG'].to_i == 1,
  )

  document_list = $opts[?D].to_a
  if document_list.any?(&:empty?)
    puts "Clearing collection #{bold{collection}}."
    $documents.clear
    document_list.reject!(&:empty?)
  end
  unless document_list.empty?
    document_list.map! do |doc|
      if doc =~ %r(\Ahttps?://)
        doc
      else
        File.expand_path(doc)
      end
    end
    puts "Collection #{bold{collection}}: Adding #{document_list.size} documents‚Ä¶"
    document_list.each_slice(25) do |docs|
      docs.each do |doc|
        fetch_source(doc) do |doc_io|
          embed_source(doc_io, doc)
        end
      end
    end
  end
else
  $documents = Tins::NULL
end

if redis_expiring_url = $config.redis.expiring.url?
  $cache = Ollama::Documents::RedisCache.new(
    prefix: 'Expiring-',
    url:    redis_expiring_url,
    ex:     $config.redis.expiring.ex,
  )
end

$current_voice = $config.voice.default

puts "Configuration read from #{config.filename.inspect} is:", $config
info
puts "\nType /help to display the chat help."

images = []
loop do
  parse_content = true
  input_prompt = bold { color(172) { message_type(images) + " user" } } + bold { "> " }
  content = Reline.readline(input_prompt, true)&.chomp

  case content
  when %r(^/paste$)
    puts bold { "Paste your content and then press C-d!" }
    content = STDIN.read
  when %r(^/copy$)
    copy_to_clipboard(messages)
    next
  when %r(^/markdown$)
    $markdown.toggle
    next
  when %r(^/stream$)
    $stream.toggle
    next
  when %r(^/voice(?:\s+(change))?$)
    if $1 == 'change'
      change_voice
    else
      $voice.toggle
    end
    next
  when %r(^/list(?:\s+(\d*))?$)
    last = if $1
             2 * $1.to_i
           end
    list_conversation(messages, last)
    next
  when %r(^/clear$)
    clear_messages(messages)
    puts "Cleared messages."
    next
  when %r(^/clobber$)
    clear_messages(messages)
    $documents.clear
    puts "Cleared messages and collection."
    next
  when %r(^/collection\s+(clear|change)(?:\s+(.+))?$)
    command, arg = $1, $2
    case command
    when 'clear'
      tags = arg.present? ? arg.sub(/\A#*/, '') : nil
      if tags
        $documents.clear(tags:)
        puts "Cleared tag ##{tags} from collection #{bold{collection}}."
      else
        $documents.clear
        puts "Cleared collection #{bold{collection}}."
      end
    when 'change'
      choose_collection(collection)
    end
    next
  when %r(^/system$)
    change_system_prompt(messages)
    info
    next
  when %r(/info)
    info
    next
  when %r(^/pop(?:\s+(\d*))?$)
    if messages.size > 1
      n = $1.to_i.clamp(1, Float::INFINITY)
      r =  messages.pop(2 * n)
      m = r.size / 2
      puts "Popped the last #{m} exchanges."
    else
      puts "No more exchanges you can pop."
    end
    list_conversation(messages, 2)
    next
  when %r(^/model$)
    $model = choose_model('', $model)
    next
  when %r(^/regenerate$)
    if content = messages[-2]&.content
      content.gsub!(/\nConsider these chunks for your answer.*\z/, '')
      messages.pop(2)
    else
      puts "Not enough messages in this conversation."
      redo
    end
    parse_content = false
    content
  when %r(^/import\s+(.+))
    parse_content = false
    content       = import($1) or next
  when %r(^/summarize\s+(?:(\d+)\s+)?(.+))
    parse_content = false
    content       = summarize($2, words: $1) or next
  when %r(^/embedding$)
    $embedding_paused.toggle(show: false)
    $embedding.show
    next
  when %r(^/embed\s+(.+))
    parse_content = false
    content       = embed($1) or next
  when %r(^/web\s+(?:(\d+)\s+)?(.+))
    parse_content   = false
    urls            = search_web($2, $1.to_i)
    urls.each do |url|
      fetch_source(url) { |url_io| embed_source(url_io, url) }
    end
    urls_summarized = urls.map { summarize(_1) }
    query   = $2.inspect
    results = urls.zip(urls_summarized).
      map { |u, s| "%s as \n:%s" % [ u, s ] } * "\n\n"
    content = $config.prompts.web % { query:, results: }
  when %r(^/save\s+(.+)$)
    save_conversation($1, messages)
    puts "Saved conversation to #$1."
    next
  when %r(^/load\s+(.+)$)
    messages = load_conversation($1)
    puts "Loaded conversation from #$1."
    next
  when %r(^/quit$)
    puts "Goodbye."
    exit 0
  when %r(^/)
    display_chat_help
    next
  when ''
    puts "Type /quit to quit."
    next
  when nil
    puts "Goodbye."
    exit 0
  end

  content, tags = if parse_content
                    parse_content(content, images)
                  else
                    [ content, Utils::Tags.new ]
                  end

  if $embedding.on? && content
    records = $documents.find_where(
      content.downcase,
      tags:,
      prompt:     $config.embedding.model.prompt?,
      text_size:  $config.embedding.found_texts_size?,
      text_count: $config.embedding.found_texts_count?,
    )
    unless records.empty?
      content += "\nConsider these chunks for your answer:\n\n"\
        "#{records.map { [ _1.text, _1.tags_set ] * ?\n }.join("\n\n---\n\n")}"
    end
  end

  messages << Message.new(role: 'user', content:, images: images.dup)
  images.clear
  handler = FollowChat.new(messages:, markdown: $markdown.on?, voice: ($current_voice if $voice.on?))
  ollama.chat(model: $model, messages:, options:, stream: $stream.on?, &handler)

  if $embedding.on? && !records.empty?
    puts "", records.map { |record|
      link = if record.source =~ %r(\Ahttps?://)
               record.source
             else
               'file://%s' % File.expand_path(record.source)
             end
      [ link, record.tags.first ]
    }.uniq.map { |l, t| hyperlink(l, t) }.join(' ')
    $config.debug and jj messages
  end
rescue Interrupt
  puts "Type /quit to quit."
end
