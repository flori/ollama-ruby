#!/usr/bin/env ruby

require 'ollama'
include Ollama
require 'term/ansicolor'
include Term::ANSIColor
require 'tins'
include Tins::GO
require 'reline'
require 'reverse_markdown'
require 'complex_config'
require 'fileutils'
require 'uri'
require 'nokogiri'
require 'rss'
require 'pdf/reader'

class OllamaChatConfig
  include ComplexConfig
  include FileUtils

  DEFAULT_CONFIG = <<~EOT
    ---
    url: <%= ENV['OLLAMA_URL'] || 'http://%s' % ENV.fetch('OLLAMA_HOST') %>
    model:
      name: <%= ENV.fetch('OLLAMA_CHAT_MODEL', 'llama3.1') %>
      options:
        num_ctx: 8192
    prompts:
      system: <%= ENV.fetch('OLLAMA_CHAT_SYSTEM', 'null') %>
      summarize: |
        Generate an abstract summary of the content in this document:

        %s
    voice: Samantha
    markdown: true
    embedding:
      enabled: true
      model:
        name: mxbai-embed-large
        options: {}
        # Retrieval prompt template:
        prompt: 'Represent this sentence for searching relevant passages: %s'
      collection: <%= ENV.fetch('OLLAMA_CHAT_COLLECTION', 'ollama_chat') %>
      found_texts_size: 4096
      found_texts_count: null
      splitter:
        name: RecursiveCharacter
        chunk_size: 1024
    cache: Ollama::Documents::RedisCache
    redis:
      url: <%= ENV.fetch('REDIS_URL', 'null') %>
    debug: <%= ENV['OLLAMA_CHAT_DEBUG'].to_i == 1 ? true : false %>
  EOT

  def initialize(filename = nil)
    @filename = filename || default_path
    @config = Provider.config(@filename, '‚öôÔ∏è')
    retried = false
  rescue ConfigurationFileMissing
    if @filename == default_path && !retried
      retried = true
      mkdir_p File.dirname(default_path)
      File.secure_write(default_path, DEFAULT_CONFIG)
      retry
    else
      raise
    end
  end

  attr_reader :filename

  attr_reader :config

  def default_path
    File.join(config_dir_path, 'config.yml')
  end

  def config_dir_path
    File.join(
      ENV.fetch(
        'XDG_CONFIG_HOME',
        File.join(ENV.fetch('HOME'), '.config')
      ),
      'ollama_chat'
    )
  end
end

class FollowChat
  include Ollama::Handlers::Concern
  include Term::ANSIColor

  def initialize(messages:, markdown: false, voice: nil, output: $stdout)
    super(output:)
    @output.sync = true
    @markdown = markdown
    @say = voice ? Handlers::Say.new(voice:) : NOP
    @messages = messages
    @user     = nil
  end

  def call(response)
    $config.debug and jj response
    if response&.message&.role == 'assistant'
      if @messages.last.role != 'assistant'
        @messages << Message.new(role: 'assistant', content: '')
        @user = message_type(@messages.last.images) + " " +
          bold { color(111) { 'assistant:' } }
        puts @user unless @markdown
      end
      content = response.message&.content
      @messages.last.content << content
      if @markdown and @messages.last.content.present?
        markdown_content = Utils::ANSIMarkdown.parse(@messages.last.content)
        @output.print clear_screen, move_home, @user, ?\n, markdown_content
      else
        @output.print content
      end
      @say.call(response)
    end
    if response.done
      @output.puts
      @output.puts 'üìä ' + color(111) { Utils::Width.wrap(eval_stats(response), percentage: 90) }
    end
    self
  end

  def eval_stats(response)
    eval_duration = response.eval_duration / 1e9
    prompt_eval_duration = response.prompt_eval_duration / 1e9
    {
      eval_duration:        Tins::Duration.new(eval_duration),
      eval_count:           response.eval_count,
      eval_rate:            "%.2f c/s" % (response.eval_count / eval_duration),
      prompt_eval_duration: Tins::Duration.new(prompt_eval_duration),
      prompt_eval_count:    response.prompt_eval_count,
      prompt_eval_rate:     "%.2f c/s" % (response.prompt_eval_count / prompt_eval_duration),
      total_duration:       Tins::Duration.new(response.total_duration / 1e9),
      load_duration:        Tins::Duration.new(response.load_duration / 1e9),
    }.map { _1 * '=' } * ' '
  end
end

def search_web(query, n = 5)
  query = URI.encode_uri_component(query)
  url = "https://www.duckduckgo.com/html/?q=#{query}"
  Ollama::Utils::Fetcher.new.get(url) do |tmp|
    result = []
    doc = Nokogiri::HTML(tmp)
    doc.css('.results_links').each do |link|
      if n > 0
        url = link.css('.result__a').first&.[]('href')
        url.sub!(%r(\A/l/\?uddg=), '')
        url.sub!(%r(&rut=.*), '')
        url = URI.decode_uri_component(url)
        url = URI.parse(url)
        url.host =~ /duckduckgo\.com/ and next
        result << url
        n -= 1
      else
        break
      end
    end
    result
  end
end

def pull_model_unless_present(model, options, retried = false)
  ollama.show(name: model) { |response|
    puts "Model #{bold{model}} with architecture "\
      "#{response.model_info['general.architecture']} found."
    if system = response.system
      puts "Configured model system prompt is:\n#{italic { system }}"
      return system
    else
      return
    end
  }
rescue Errors::NotFoundError
  puts "Model #{bold{model}} not found, attempting to pull it now‚Ä¶"
  ollama.pull(name: model)
  if retried
    exit 1
  else
    retried = true
    retry
  end
rescue Errors::Error => e
  warn "Caught #{e.class}: #{e} => Exiting."
  exit 1
end

def load_conversation(filename)
  unless File.exist?(filename)
    puts "File #{filename} doesn't exist. Choose another filename."
    return
  end
  File.open(filename, 'r') do |output|
    return JSON(output.read).map { Ollama::Message.from_hash(_1) }
  end
end

def save_conversation(filename, messages)
  if File.exist?(filename)
    puts "File #{filename} already exists. Choose another filename."
    return
  end
  File.open(filename, 'w') do |output|
    output.puts JSON(messages)
  end
end

def message_type(images)
  if images.present?
    ?üì∏
  else
    ?üì®
  end
end

def list_conversation(messages, markdown)
  messages.each do |m|
    role_color = case m.role
                 when 'user' then 172
                 when 'assistant' then 111
                 when 'system' then 213
                 else 210
                 end
    content = if markdown && m.content.present?
                Utils::ANSIMarkdown.parse(m.content)
              else
                m.content
              end
    message_text = message_type(m.images) + " "
    message_text += bold { color(role_color) { m.role } }
    message_text += ":\n#{content}"
    if m.images.present?
      message_text += "\nImages: " + italic { m.images.map(&:path) * ', ' }
    end
    puts message_text
  end
end

def reverse_markdown(html)
  ReverseMarkdown.convert(
    html,
    unknown_tags: :bypass,
    github_flavored: true,
    tag_border: ''
  )
end

def parse_rss(source_io)
  feed = RSS::Parser.parse(source_io, false, false)
  title = <<~end
    # #{feed&.channel&.title}

  end
  feed.items.inject(title) do |text, item|
    text << <<~end
      ## [#{item&.title}](#{item&.link})

      updated on #{item&.pubDate}

      #{reverse_markdown(item&.description)}

    end
  end
end

def parse_atom(source_io)
  feed = RSS::Parser.parse(source_io, false, false)
  title = <<~end
    # #{feed.title.content}

  end
  feed.items.inject(title) do |text, item|
    text << <<~end
      ## [#{item&.title&.content}](#{item&.link&.href})

      updated on #{item&.updated&.content}

      #{reverse_markdown(item&.content&.content)}

    end
  end
end

def parse_source(source_io)
  case source_io&.content_type
  when 'text/html'
    reverse_markdown(source_io.read)
  when 'text/xml'
    if source_io.readline =~ %r(^\s*<rss\s)
      source_io.rewind
      return parse_rss(source_io)
    end
    source_io.rewind
    source_io.read
  when %r(\Atext/)
    source_io.read
  when 'application/rss+xml'
    parse_rss(source_io)
  when 'application/atom+xml'
    parse_atom(source_io)
  when 'application/json'
    source_io.read
  when 'application/pdf'
    reader = PDF::Reader.new(source_io)
    result = +''
    reader.pages.each do |page|
      result << page.text
    end
    result
  else
    STDERR.puts "Cannot import #{source_io&.content_type} document."
    return
  end
end

def import_document(source_io, source)
  unless $config.embedding.enabled
    STDOUT.puts "Embedding disabled, I won't import any documents, try: /summarize"
    return
  end
  puts "Importing #{italic { source_io.content_type }} document #{source.to_s.inspect}."
  text = parse_source(source_io) or return
  text.downcase!
  splitter_config = $config.embedding.splitter
  inputs = case splitter_config.name
           when 'Character'
             Ollama::Documents::Splitters::Character.new(
               chunk_size: splitter_config.chunk_size,
             ).split(text)
           when 'RecursiveCharacter'
             Ollama::Documents::Splitters::RecursiveCharacter.new(
               chunk_size: splitter_config.chunk_size,
             ).split(text)
           when 'Semantic'
             Ollama::Documents::Splitters::Semantic.new(
               ollama:, model: $config.embedding.model.name,
               chunk_size: splitter_config.chunk_size,
             ).split(
               text,
               breakpoint: splitter_config.breakpoint.to_sym,
               percentage: splitter_config.percentage?,
               percentile: splitter_config.percentile?,
             )
           end
  $documents.add(inputs, source: source.to_s)
end

def add_image(images, source_io, source)
  STDERR.puts "Adding #{source_io.content_type} image #{source.to_s.inspect}."
  image = Image.for_io(source_io, path: source.to_s)
  (images << image).uniq!
end

def fetch_source(source, &block)
  case source
  when %r(\Ahttps?://\S+)
    Utils::Fetcher.get(source) do |tmp|
      block.(tmp)
    end
  when %r(\Afile://(?:(?:[.-]|[[:alnum:]])*)(/\S*)|([~.]?/\S*))
    filename = $~.captures.compact.first
    filename = File.expand_path(filename)
    Utils::Fetcher.read(filename) do |tmp|
      block.(tmp)
    end
  else
    raise "invalid source"
  end
rescue => e
  STDERR.puts "Cannot add source #{source.to_s.inspect}: #{e}\n#{e.backtrace * ?\n}"
end

def summarize(source)
  puts "Now summarizing #{source.to_s.inspect}."
  source_content =
    fetch_source(source) do |source_io|
      parse_source(source_io) or return
    end
  $config.prompts.summarize % source_content
end

def parse_content(content, images)
  images.clear
  tags = Utils::Tags.new

  content.scan(%r([.~]?/\S+|https?://\S+|#\S+)).each do |source|
    case source
    when /\A#(\S+)/
      tags << $1
    else
      source = source.sub(/(["')]|\*+)\z/, '')
      fetch_source(source) do |source_io|
        case source_io&.content_type&.media_type
        when 'image'
          add_image(images, source_io, source)
        when 'text', 'application'
          import_document(source_io, source)
        else
          STDERR.puts(
            "Cannot fetch #{source.to_s.inspect} with content type "\
            "#{source_io&.content_type.inspect}"
          )
        end
      end
    end
  end

  return content, (tags unless tags.empty?)
end

def choose_model(cli_model, default_model)
  models = ollama.tags.models.map(&:name).sort
  model = if cli_model == ''
            Ollama::Utils::Chooser.choose(models) || default_model
          else
            cli_model || default_model
          end
ensure
  puts green { "Connecting to #{model}@#{ollama.base_url} now‚Ä¶" }
end

def choose_collection(default_collection)
  collections = [ default_collection ] + $documents.collections
  collections = collections.uniq.sort
  $documents.collection = collection =
    Ollama::Utils::Chooser.choose(collections) || default_collection
ensure
  puts "Changing to collection #{bold{collection}}."
  collection_stats
end

def collection_stats
  puts <<~end
    Collection
      Name: #{bold{$documents.collection}}
      #Embeddings: #{$documents.size}
      Tags: #{$documents.tags}
  end
end

def configure_cache
  Object.const_get($config.cache)
rescue => e
  STDERR.puts "Caught #{e.class}: #{e} => Falling back to MemoryCache."
  Ollama::Documents::MemoryCache
end

def set_markdown(value)
  if value
    puts "Using ANSI markdown to output content."
    true
  else
    puts "Using plaintext for outputting content."
    false
  end
end

def display_chat_help
  puts <<~end
    /paste                                   to paste content
    /markdown                                toggle markdown output
    /list                                    list the messages of the conversation
    /clear                                   clear the conversation messages
    /clobber                                 clear conversation messages and collection
    /pop [n]                                 pop the last n exchanges, defaults to 1
    /model                                   change the model
    /regenerate                              the last answer message
    /collection clear [tag]|stats|change|new clear or show stats of current collection
    /summarize source                        summarize the URL/file source's content
    /web [n] query                           query web search & return n or 1 results
    /save filename                           store conversation messages
    /load filename                           load conversation messages
    /quit                                    to quit
    /help                                    to view this help
  end
end

def usage
  puts <<~end
    #{File.basename($0)} [OPTIONS]

      -f CONFIG      config file to read
      -u URL         the ollama base url, OLLAMA_URL
      -m MODEL       the ollama model to chat with, OLLAMA_CHAT_MODEL
      -s SYSTEM      the system prompt to use as a file, OLLAMA_CHAT_SYSTEM
      -c CHAT        a saved chat conversation to load
      -C COLLECTION  name of the collection used in this conversation
      -D DOCUMENT    load document and add to collection (multiple)
      -v             use voice output
      -h             this help

  end
  exit 0
end

def ollama
  $ollama
end

opts = go 'f:u:m:s:c:C:D:vh'

config = OllamaChatConfig.new(opts[?f])
$config = config.config

opts[?h] and usage

puts "Configuration read from #{config.filename.inspect} is:", $config

base_url = opts[?u] || $config.url
$ollama      = Client.new(base_url:, debug: $config.debug)

model        = choose_model(opts[?m], $config.model.name)
options      = Options[$config.model.options]
model_system = pull_model_unless_present(model, options)
messages     = []

if $config.embedding.enabled
  embedding_model         = $config.embedding.model.name
  embedding_model_options = Options[$config.embedding.model.options]
  pull_model_unless_present(embedding_model, embedding_model_options)
  collection = opts[?C] || $config.embedding.collection
  $documents = Documents.new(
    ollama:,
    model:         $config.embedding.model.name,
    model_options: $config.embedding.model.options,
    collection:,
    cache:         configure_cache,
    redis_url:     $config.redis.url?,
  )

  document_list = opts[?D].to_a
  if document_list.any?(&:empty?)
    puts "Clearing collection #{bold{collection}}."
    $documents.clear
    document_list.reject!(&:empty?)
  end
  unless document_list.empty?
    document_list.map! do |doc|
      if doc =~ %r(\Ahttps?://)
        doc
      else
        File.expand_path(doc)
      end
    end
    puts "Collection #{bold{collection}}: Adding #{document_list.size} documents‚Ä¶"
    document_list.each_slice(25) do |docs|
      docs.each do |doc|
        fetch_source(doc) do |doc_io|
          import_document(doc_io, doc)
        end
      end
    end
  end
  collection_stats
else
  $documents = Documents.new(ollama:, model:)
end

if voice = ($config.voice if opts[?v])
  puts "Using voice #{bold{voice}} to speak."
end
markdown = set_markdown($config.markdown)

if opts[?c]
  messages.concat load_conversation(opts[?c])
else
  if system = Ollama::Utils::FileArgument.
      get_file_argument(opts[?s], default: $config.prompts.system? || model_system)
    messages << Message.new(role: 'system', content: system)
    puts "Configured system prompt is:\n#{italic { system }}"
  end
end

puts "\nType /help to display the chat help."

images = []
loop do
  parse_content = true
  input_prompt = bold { color(172) { message_type(images) + " user" } } + bold { "> " }
  content = Reline.readline(input_prompt, true)&.chomp

  case content
  when %r(^/paste$)
    puts bold { "Paste your content and then press C-d!" }
    content = STDIN.read
  when %r(^/quit$)
    puts "Goodbye."
    exit 0
  when %r(^/markdown$)
    markdown = set_markdown(!markdown)
    next
  when %r(^/list$)
    list_conversation(messages, markdown)
    next
  when %r(^/clear$)
    messages.clear
    puts "Cleared messages."
    next
  when %r(^/clobber$)
    messages.clear
    $documents.clear
    puts "Cleared messages and collection."
    next
  when %r(^/collection\s+(clear|stats|change|new)(?:\s+(.+))?$)
    command, arg = $1, $2
    case command
    when 'clear'
      tags = arg.present? ? arg.sub(/\A#*/, '') : nil
      if tags
        $documents.clear(tags:)
        puts "Cleared tag ##{tags} from collection #{bold{collection}}."
      else
        $documents.clear
        puts "Cleared collection #{bold{collection}}."
      end
    when 'stats'
      collection_stats
    when 'change'
      choose_collection(collection)
    when 'new'
      print "Enter name of the new collection: "
      $documents.collection = collection = STDIN.gets.chomp
      collection_stats
    end
    next
  when %r(^/pop?(?:\s+(\d*))?$)
    n = $1.to_i.clamp(1, Float::INFINITY)
    r =  messages.pop(2 * n)
    m = r.size / 2
    puts "Popped the last #{m} exchanges."
    next
  when %r(^/model$)
    model = choose_model('', model)
    next
  when %r(^/regenerate$)
    if content = messages[-2]&.content
      content.gsub!(/\nConsider these chunks for your answer.*\z/, '')
      messages.pop(2)
    else
      puts "Not enough messages in this conversation."
      redo
    end
  when %r(^/summarize\s+(.+))
    parse_content = false
    content       = summarize($1) or next
  when %r(^/web\s+(?:(\d+)\s+)?(.+))
    parse_content   = false
    urls            = search_web($2, $1.to_i)
    urls.each do |url|
      fetch_source(url) do |url_io|
        import_document(url_io, url)
      end
    end
    urls_summarized = urls.map { summarize(_1) }
    content = <<~end
      Answer the the query #{$2.inspect} using these sources and summaries:

      #{urls.zip(urls_summarized).map { |u, s| "%s as \n:%s" % [ u, s ] } * "\n\n"}
    end
  when %r(^/save\s+(.+)$)
    save_conversation($1, messages)
    puts "Saved conversation to #$1."
    next
  when %r(^/load\s+(.+)$)
    messages = load_conversation($1)
    puts "Loaded conversation from #$1."
    next
  when %r(^/)
    display_chat_help
    next
  when nil, ''
    puts "Type /quit to quit."
    next
  end

  content, tags = if parse_content
                    parse_content(content, images.clear)
                  else
                    [ content, Utils::Tags.new ]
                  end

  if $config.embedding.enabled && content
    records = $documents.find_where(
      content.downcase,
      tags:,
      prompt:     $config.embedding.model.prompt?,
      text_size:  $config.embedding.found_texts_size?,
      text_count: $config.embedding.found_texts_count?,
    )
    found_texts = records.map(&:text)
    unless found_texts.empty?
      content += "\nConsider these chunks for your answer:\n"\
        "#{found_texts.join("\n\n---\n\n")}"
    end
  end

  messages << Message.new(role: 'user', content:, images:)
  handler = FollowChat.new(messages:, markdown:, voice:)
  ollama.chat(model:, messages:, options:, stream: true, &handler)

  if records
    puts records.map { |record|
      link = if record.source =~ %r(\Ahttps?://)
               record.source
             else
               'file://%s' % File.expand_path(record.source)
             end
      [ link, record.tags.first ]
    }.uniq.map { |l, t| hyperlink(l, t) }.join(' ')
    $config.debug and jj messages
  end
rescue Interrupt
  puts "Type /quit to quit."
end
