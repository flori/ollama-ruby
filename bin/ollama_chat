#!/usr/bin/env ruby

require 'ollama'
include Ollama
include Tins::GO
require 'term/ansicolor'
include Term::ANSIColor
require 'reline'
require 'reverse_markdown'
require 'complex_config'
require 'fileutils'
require 'uri'
require 'nokogiri'
require 'rss'
require 'pdf/reader'
require 'csv'
require 'xdg'

class OllamaChatConfig
  include ComplexConfig
  include FileUtils

  DEFAULT_CONFIG = <<~EOT
    ---
    url: <%= ENV['OLLAMA_URL'] || 'http://%s' % ENV.fetch('OLLAMA_HOST') %>
    proxy: null # http://localhost:8080
    model:
      name: <%= ENV.fetch('OLLAMA_CHAT_MODEL', 'llama3.1') %>
      options:
        num_ctx: 8192
    location:
      enabled: false
      name: Berlin
      decimal_degrees: [ 52.514127, 13.475211 ]
      units: SI (International System of Units) # or USCS (United States Customary System)
    prompts:
      embed: "This source was now embedded: %{source}"
      summarize: |
        Generate an abstract summary of the content in this document using
        %{words} words:

        %{source_content}
      web: |
        Answer the the query %{query} using these sources and summaries:

        %{results}
    system_prompts:
      default: <%= ENV.fetch('OLLAMA_CHAT_SYSTEM', 'null') %>
    voice:
      enabled: false
      default: Samantha
      list: <%= `say -v ? 2>/dev/null`.lines.map { _1[/^(.+?)\s+[a-z]{2}_[a-zA-Z0-9]{2,}/, 1] }.uniq.sort.to_s.force_encoding('ASCII-8BIT') %>
    markdown: true
    stream: true
    document_policy: importing
    embedding:
      enabled: true
      model:
        name: mxbai-embed-large
        embedding_length: 1024
        options: {}
        # Retrieval prompt template:
        prompt: 'Represent this sentence for searching relevant passages: %s'
      batch_size: 10
      database_filename: null # ':memory:'
      collection: <%= ENV['OLLAMA_CHAT_COLLECTION'] %>
      found_texts_size: 4096
      found_texts_count: 10
      splitter:
        name: RecursiveCharacter
        chunk_size: 1024
    cache: Ollama::Documents::RedisBackedMemoryCache
    redis:
      documents:
        url: <%= ENV.fetch('REDIS_URL', 'null') %>
      expiring:
        url: <%= ENV.fetch('REDIS_EXPIRING_URL', 'null') %>
        ex: 86400
    debug: <%= ENV['OLLAMA_CHAT_DEBUG'].to_i == 1 ? true : false %>
    ssl_no_verify: []
    copy: pbcopy
  EOT

  def initialize(filename = nil)
    @filename = filename || default_path
    unless File.directory?(cache_dir_path)
      mkdir_p cache_dir_path.to_s
    end
    @config = Provider.config(@filename, '‚öôÔ∏è')
    retried = false
  rescue ConfigurationFileMissing
    if @filename == default_path && !retried
      retried = true
      mkdir_p config_dir_path.to_s
      File.secure_write(default_path, DEFAULT_CONFIG)
      retry
    else
      raise
    end
  end

  attr_reader :filename

  attr_reader :config

  def default_path
    config_dir_path + 'config.yml'
  end

  def config_dir_path
    XDG.new.config_home + 'ollama_chat'
  end

  def cache_dir_path
    XDG.new.cache_home + 'ollama_chat'
  end

  def database_path
    cache_dir_path + 'documents.db'
  end
end

class FollowChat
  include Handlers::Concern
  include Term::ANSIColor

  def initialize(messages:, markdown: false, voice: nil, output: $stdout)
    super(output:)
    @output.sync = true
    @markdown    = markdown
    @say         = voice ? Handlers::Say.new(voice:) : NOP
    @messages    = messages
    @user        = nil
  end

  def call(response)
    $config.debug and jj response
    if response&.message&.role == 'assistant'
      if @messages.last.role != 'assistant'
        @messages << Message.new(role: 'assistant', content: '')
        @user = message_type(@messages.last.images) + " " +
          bold { color(111) { 'assistant:' } }
        puts @user unless @markdown
      end
      content = response.message&.content
      @messages.last.content << content
      if @markdown and content = @messages.last.content.full?
        markdown_content = Kramdown::ANSI.parse(content)
        @output.print clear_screen, move_home, @user, ?\n, markdown_content
      else
        @output.print content
      end
      @say.call(response)
    end
    if response.done
      @output.puts "", eval_stats(response)
    end
    self
  end

  def eval_stats(response)
    eval_duration = response.eval_duration / 1e9
    prompt_eval_duration = response.prompt_eval_duration / 1e9
    stats_text = {
      eval_duration:        Tins::Duration.new(eval_duration),
      eval_count:           response.eval_count.to_i,
      eval_rate:            bold { "%.2f c/s" % (response.eval_count.to_i / eval_duration) } + color(111),
      prompt_eval_duration: Tins::Duration.new(prompt_eval_duration),
      prompt_eval_count:    response.prompt_eval_count.to_i,
      prompt_eval_rate:     bold { "%.2f c/s" % (response.prompt_eval_count.to_i / prompt_eval_duration) } + color(111),
      total_duration:       Tins::Duration.new(response.total_duration / 1e9),
      load_duration:        Tins::Duration.new(response.load_duration / 1e9),
    }.map { _1 * '=' } * ' '
    'üìä ' + color(111) {
      Kramdown::ANSI::Width.wrap(stats_text, percentage: 90).gsub(/(?<!\A)^/, '   ')
    }
  end
end

module Switches
  module CheckSwitch
    extend Tins::Concern

    included do
      alias_method :on?, :value
    end

    def off?
      !on?
    end

    def show
      puts @msg[value]
    end
  end

  class Switch
    def initialize(name, msg:, config: $config)
      @value = [ false, true ].include?(config) ? config : !!config.send("#{name}?")
      @msg   = msg
    end

    attr_reader :value

    def set(value, show: false)
      @value = !!value
      show && self.show
    end

    def toggle(show: true)
      @value = !@value
      show && self.show
    end

    include CheckSwitch
  end

  class CombinedSwitch
    def initialize(value:, msg:)
      @value = value
      @msg   = msg
    end

    def value
      @value.()
    end

    include CheckSwitch
  end

  def setup_switches
    $markdown = Switch.new(
      :markdown,
      msg: {
        true  => "Using #{italic{'ANSI'}} markdown to output content.",
        false => "Using plaintext for outputting content.",
      }
    )

    $stream = Switch.new(
      :stream,
      msg: {
        true  => "Streaming enabled.",
        false => "Streaming disabled.",
      }
    )

    $voice = Switch.new(
      :stream,
      msg: {
        true  => "Voice output enabled.",
        false => "Voice output disabled.",
      },
      config: $config.voice
    )

    $embedding_enabled = Switch.new(
      :embedding_enabled,
      msg: {
        true  => "Embedding enabled.",
        false => "Embedding disabled.",
      }
    )

    $embedding_paused = Switch.new(
      :embedding_paused,
      msg: {
        true  => "Embedding paused.",
        false => "Embedding resumed.",
      }
    )

    $embedding = CombinedSwitch.new(
      value: -> { $embedding_enabled.on? && $embedding_paused.off? },
      msg: {
        true  => "Embedding is currently performed.",
        false => "Embedding is currently not performed.",
      }
    )

    $location = Switch.new(
      :location,
      msg: {
        true  => "Location and localtime enabled.",
        false => "Location and localtime disabled.",
      },
      config: $config.location.enabled
    )
  end
end
include Switches

def pull_model_unless_present(model, options, retried = false)
  ollama.show(name: model) { |response|
    puts "Model #{bold{model}} with architecture "\
      "#{response.model_info['general.architecture']} found."
    if system = response.system
      puts "Configured model system prompt is:\n#{italic { system }}"
      return system
    else
      return
    end
  }
rescue Errors::NotFoundError
  puts "Model #{bold{model}} not found locally, attempting to pull it from remote now‚Ä¶"
  ollama.pull(name: model)
  if retried
    exit 1
  else
    retried = true
    retry
  end
rescue Errors::Error => e
  warn "Caught #{e.class} while pulling model: #{e} => Exiting."
  exit 1
end

def search_web(query, n = nil)
  if l = at_location
    query += " #{at_location}"
  end
  n = n.to_i
  n < 1 and n = 1
  query = URI.encode_uri_component(query)
  url = "https://www.duckduckgo.com/html/?q=#{query}"
  Utils::Fetcher.get(url, debug: $config.debug) do |tmp|
    result = []
    doc = Nokogiri::HTML(tmp)
    doc.css('.results_links').each do |link|
      if n > 0
        url = link.css('.result__a').first&.[]('href')
        url.sub!(%r(\A(//duckduckgo\.com)?/l/\?uddg=), '')
        url.sub!(%r(&rut=.*), '')
        url = URI.decode_uri_component(url)
        url = URI.parse(url)
        url.host =~ /duckduckgo\.com/ and next
        result << url
        n -= 1
      else
        break
      end
    end
    result
  end
end

def load_conversation(filename)
  unless File.exist?(filename)
    puts "File #{filename} doesn't exist. Choose another filename."
    return
  end
  File.open(filename, 'r') do |output|
    return JSON(output.read).map { Message.from_hash(_1) }
  end
end

def save_conversation(filename, messages)
  if File.exist?(filename)
    puts "File #{filename} already exists. Choose another filename."
    return
  end
  File.open(filename, 'w') do |output|
    output.puts JSON(messages)
  end
end

def message_type(images)
  images.present? ? ?üì∏ : ?üì®
end

def list_conversation(messages, last = nil)
  last = (last || messages.size).clamp(0, messages.size)
  messages[-last..-1].to_a.each do |m|
    role_color = case m.role
                 when 'user' then 172
                 when 'assistant' then 111
                 when 'system' then 213
                 else 210
                 end
    content = m.content.full? { $markdown.on? ? Kramdown::ANSI.parse(_1) : _1 }
    message_text = message_type(m.images) + " "
    message_text += bold { color(role_color) { m.role } }
    message_text += ":\n#{content}"
    m.images.full? { |images|
      message_text += "\nImages: " + italic { images.map(&:path) * ', ' }
    }
    puts message_text
  end
end

module SourceParsing
  def parse_source(source_io)
    case source_io&.content_type
    when 'text/html'
      reverse_markdown(source_io.read)
    when 'text/xml'
      if source_io.readline =~ %r(^\s*<rss\s)
        source_io.rewind
        return parse_rss(source_io)
      end
      source_io.rewind
      source_io.read
    when 'text/csv'
      parse_csv(source_io)
    when 'application/rss+xml'
      parse_rss(source_io)
    when 'application/atom+xml'
      parse_atom(source_io)
    when 'application/postscript'
      ps_read(source_io)
    when 'application/pdf'
      pdf_read(source_io)
    when %r(\Aapplication/(json|ld\+json|x-ruby|x-perl|x-gawk|x-python|x-javascript|x-c?sh|x-dosexec|x-shellscript|x-tex|x-latex|x-lyx|x-bibtex)), %r(\Atext/), nil
      source_io.read
    else
      STDERR.puts "Cannot embed #{source_io&.content_type} document."
      return
    end
  end

  def parse_csv(source_io)
    result = +''
    CSV.table(File.new(source_io), col_sep: ?,).each do |row|
      next if row.fields.select(&:present?).size == 0
      result << row.map { |pair|
        pair.compact.map { _1.to_s.strip } * ': ' if pair.last.present?
      }.select(&:present?).map { _1.prepend('  ') } * ?\n
      result << "\n\n"
    end
    result
  end

  def parse_rss(source_io)
    feed = RSS::Parser.parse(source_io, false, false)
    title = <<~EOT
      # #{feed&.channel&.title}

    EOT
    feed.items.inject(title) do |text, item|
      text << <<~EOT
        ## [#{item&.title}](#{item&.link})

        updated on #{item&.pubDate}

        #{reverse_markdown(item&.description)}

      EOT
    end
  end

  def parse_atom(source_io)
    feed = RSS::Parser.parse(source_io, false, false)
    title = <<~EOT
      # #{feed.title.content}

    EOT
    feed.items.inject(title) do |text, item|
      text << <<~EOT
        ## [#{item&.title&.content}](#{item&.link&.href})

        updated on #{item&.updated&.content}

        #{reverse_markdown(item&.content&.content)}

      EOT
    end
  end

  def pdf_read(io)
    reader = PDF::Reader.new(io)
    reader.pages.inject(+'') { |result, page| result << page.text }
  end

  def ps_read(io)
    gs = `which gs`.chomp
    if gs.present?
      Tempfile.create do |tmp|
        IO.popen("#{gs} -q -sDEVICE=pdfwrite -sOutputFile=#{tmp.path} -", 'wb') do |gs_io|
          until io.eof?
            buffer = io.read(1 << 17)
            IO.select(nil, [ gs_io ], nil)
            gs_io.write buffer
          end
          gs_io.close
          File.open(tmp.path, 'rb') do |pdf|
            pdf_read(pdf)
          end
        end
      end
    else
      STDERR.puts "Cannot convert #{io&.content_type} whith ghostscript, gs not in path."
    end
  end

  def reverse_markdown(html)
    ReverseMarkdown.convert(
      html,
      unknown_tags: :bypass,
      github_flavored: true,
      tag_border: ''
    )
  end
end
include SourceParsing

def http_options(url)
  options = {}
  if ssl_no_verify = $config.ssl_no_verify?
    hostname = URI.parse(url).hostname
    options |= { ssl_verify_peer: !ssl_no_verify.include?(hostname) }
  end
  if proxy = $config.proxy?
    options |= { proxy: }
  end
  options
end

def fetch_source(source, &block)
  case source
  when %r(\A!(.*))
    command = $1
    Utils::Fetcher.execute(command) do |tmp|
      block.(tmp)
    end
  when %r(\Ahttps?://\S+)
    Utils::Fetcher.get(
      source,
      cache:        $cache,
      debug:        $config.debug,
      http_options: http_options(Utils::Fetcher.normalize_url(source))
    ) do |tmp|
      block.(tmp)
    end
  when %r(\Afile://(/\S*)|\A((?:\.\.|[~.]?)/\S*))
    filename = $~.captures.compact.first
    filename = File.expand_path(filename)
    Utils::Fetcher.read(filename) do |tmp|
      block.(tmp)
    end
  else
    raise "invalid source"
  end
rescue => e
  STDERR.puts "Cannot fetch source #{source.to_s.inspect}: #{e.class} #{e}\n#{e.backtrace * ?\n}"
end

def add_image(images, source_io, source)
  STDERR.puts "Adding #{source_io&.content_type} image #{source.to_s.inspect}."
  image = Image.for_io(source_io, path: source.to_s)
  (images << image).uniq!
end

def import_source(source_io, source)
  source = source.to_s
  puts "Importing #{italic { source_io&.content_type }} document #{source.to_s.inspect} now."
  source_content = parse_source(source_io)
  "Imported #{source.inspect}:\n#{source_content}\n\n"
end

def import(source)
  fetch_source(source) do |source_io|
    content = import_source(source_io, source) or return
    source_io.rewind
    content
  end
end

def summarize_source(source_io, source, words: nil)
  puts "Summarizing #{italic { source_io&.content_type }} document #{source.to_s.inspect} now."
  words = words.to_i
  words < 1 and words = 100
  source_content = parse_source(source_io)
  source_content.present? or return
  $config.prompts.summarize % { source_content:, words: }
end

def summarize(source, words: nil)
  fetch_source(source) do |source_io|
    content = summarize_source(source_io, source, words:) or return
    source_io.rewind
    content
  end
end

def embed_source(source_io, source, count: nil)
  $embedding.on? or return parse_source(source_io)
  m = "Embedding #{italic { source_io&.content_type }} document #{source.to_s.inspect}."
  if count
    puts '%u. %s' % [ count, m ]
  else
    puts m
  end
  text = parse_source(source_io) or return
  text.downcase!
  splitter_config = $config.embedding.splitter
  inputs = nil
  case splitter_config.name
  when 'Character'
    splitter = Documents::Splitters::Character.new(
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(text)
  when 'RecursiveCharacter'
    splitter = Documents::Splitters::RecursiveCharacter.new(
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(text)
  when 'Semantic'
    splitter = Documents::Splitters::Semantic.new(
      ollama:, model: $config.embedding.model.name,
      chunk_size: splitter_config.chunk_size,
    )
    inputs = splitter.split(
      text,
      breakpoint: splitter_config.breakpoint.to_sym,
      percentage: splitter_config.percentage?,
      percentile: splitter_config.percentile?,
    )
  end
  inputs or return
  source = source.to_s
  if source.start_with?(?!)
    source = Kramdown::ANSI::Width.truncate(
      source[1..-1].gsub(/\W+/, ?_),
      length: 10
    )
  end
  $documents.add(inputs, source:, batch_size: $config.embedding.batch_size?)
end

def embed(source)
  if $embedding.on?
    puts "Now embedding #{source.to_s.inspect}."
    fetch_source(source) do |source_io|
      content = parse_source(source_io)
      content.present? or return
      source_io.rewind
      embed_source(source_io, source)
    end
    $config.prompts.embed % { source: }
  else
    puts "Embedding is off, so I will just give a small summary of this source."
    summarize(source)
  end
end

def parse_content(content, images)
  images.clear
  tags = Utils::Tags.new

  contents = [ content ]
  content.scan(%r((https?://\S+)|(#\S+)|(?:file://)?(\S*\/\S+))).each do |url, tag, file|
    case
    when tag
      tags.add(tag)
      next
    when file
      file = file.sub(/#.*/, '')
      file =~ %r(\A[~./]) or file.prepend('./')
      File.exist?(file) or next
      source = file
    when url
      source = url
    end
    fetch_source(source) do |source_io|
      case source_io&.content_type&.media_type
      when 'image'
        add_image(images, source_io, source)
      when 'text', 'application', nil
        case $document_policy
        when 'ignoring'
          nil
        when 'importing'
          contents << import_source(source_io, source)
        when 'embedding'
          embed_source(source_io, source)
        when 'summarizing'
          contents << summarize_source(source_io, source)
        end
      else
        STDERR.puts(
          "Cannot fetch #{source.to_s.inspect} with content type "\
          "#{source_io&.content_type.inspect}"
        )
      end
    end
  end
  new_content = contents.select { _1.present? rescue nil }.compact * "\n\n"
  return new_content, (tags unless tags.empty?)
end

def choose_model(cli_model, current_model)
  models = ollama.tags.models.map(&:name).sort
  model = if cli_model == ''
            Utils::Chooser.choose(models) || current_model
          else
            cli_model || current_model
          end
ensure
  puts green { "Connecting to #{model}@#{ollama.base_url} now‚Ä¶" }
end

def ask?(prompt:)
  print prompt
  STDIN.gets.chomp
end

def choose_collection(current_collection)
  collections = [ current_collection ] + $documents.collections
  collections = collections.compact.map(&:to_s).uniq.sort
  collections.unshift('[EXIT]').unshift('[NEW]')
  collection = Utils::Chooser.choose(collections) || current_collection
  case collection
  when '[NEW]'
    $documents.collection = ask?(prompt: "Enter name of the new collection: ")
  when nil, '[EXIT]'
    puts "Exiting chooser."
  when /./
    $documents.collection = collection
  end
ensure
  puts "Using collection #{bold{$documents.collection}}."
  info
end

def choose_document_policy
  policies = %w[ importing embedding summarizing ignoring ].sort
  current  = if policies.index($document_policy)
               $document_policy
             elsif policies.index($config.document_policy)
               $config.document_policy
             else
               policies.first
             end
  policies.unshift('[EXIT]')
  policy = Utils::Chooser.choose(policies)
  case policy
  when nil, '[EXIT]'
    puts "Exiting chooser."
    policy = current
  end
  $document_policy = policy
ensure
  puts "Using document policy #{bold{$document_policy}}."
  info
end

def collection_stats
  list = $documents.collections.sort.map { |c|
    '  ' + ($documents.collection == c ? bold { c } : c).to_s
  }.join(?\n)
  puts <<~EOT
    Current Collection
      Name: #{bold{$documents.collection}}
      #Embeddings: #{$documents.size}
      #Tags: #{$documents.tags.size}
      Tags: #{$documents.tags}
    List:
    #{list}
  EOT
end

def configure_cache
  if $opts[?M]
    Documents::MemoryCache
  else
    Object.const_get($config.cache)
  end
rescue => e
  STDERR.puts "Caught #{e.class}: #{e} => Falling back to MemoryCache."
  Documents::MemoryCache
end

def show_system_prompt
  puts <<~EOT
    Configured system prompt is:
    #{Kramdown::ANSI.parse($system.to_s).gsub(/\n+\z/, '').full? || 'n/a'}
  EOT
end

def at_location
  if $location.on?
    location_name            = $config.location.name
    location_decimal_degrees = $config.location.decimal_degrees * ', '
    localtime                = Time.now.iso8601
    units                    = $config.location.units
    $config.prompts.location % {
      location_name:, location_decimal_degrees:, localtime:, units:,
    }
  end.to_s
end

def set_system_prompt(messages, system)
  $system = system
  messages.clear
  messages << Message.new(role: 'system', content: system)
end

def change_system_prompt(messages, default, system: nil)
  selector = Regexp.new(system.to_s[1..-1].to_s)
  prompts  = $config.system_prompts.attribute_names.compact.grep(selector)
  chosen   = Utils::Chooser.choose(prompts, return_immediately: true)
  system   = if chosen
              $config.system_prompts.send(chosen)
            else
              default
            end
  set_system_prompt(messages, system)
end

def change_voice
  chosen  = Utils::Chooser.choose($config.voice.list)
  $current_voice = chosen.full? || $config.voice.default
end

def info
  puts "Current model is #{bold{$model}}."
  if $model_options.present?
    puts "  Options: #{JSON.pretty_generate($model_options).gsub(/(?<!\A)^/, '  ')}"
  end
  $embedding.show
  if $embedding.on?
    puts "Embedding model is #{bold{$embedding_model}}"
    if $embedding_model_options.present?
      puts "  Options: #{JSON.pretty_generate($embedding_model_options).gsub(/(?<!\A)^/, '  ')}"
    end
    puts "Text splitter is #{bold{$config.embedding.splitter.name}}."
    collection_stats
  end
  puts "Documents database cache is #{$documents.nil? ? 'n/a' : bold{$documents.cache.class}}"
  $markdown.show
  $stream.show
  $location.show
  puts "Document policy for references in user text: #{bold{$document_policy}}"
  if $voice.on?
    puts "Using voice #{bold{$current_voice}} to speak."
  end
  show_system_prompt
end

def clear_messages(messages)
  messages.delete_if { _1.role != 'system' }
end

def copy_to_clipboard(messages)
  if message = messages.last and message.role == 'assistant'
    copy = `which #{$config.copy}`.chomp
    if copy.present?
      IO.popen(copy, 'w') do |clipboard|
        clipboard.write(message.content)
      end
      STDOUT.puts "The last response has been copied to the system clipboard."
    else
      STDERR.puts "#{$config.copy.inspect} command not found in system's path!"
    end
  else
    STDERR.puts "No response available to copy to the system clipboard."
  end
end

def display_chat_help
  puts <<~EOT
    /copy                           to copy last response to clipboard
    /paste                          to paste content
    /markdown                       toggle markdown output
    /stream                         toggle stream output
    /location                       toggle location submission
    /voice( change)                 toggle voice output or change the voice
    /list [n]                       list the last n / all conversation exchanges
    /clear                          clear the whole conversation
    /clobber                        clear the conversation and collection
    /pop [n]                        pop the last n exchanges, defaults to 1
    /model                          change the model
    /system                         change system prompt (clears conversation)
    /regenerate                     the last answer message
    /collection( clear|change)      change (default) collection or clear
    /info                           show information for current session
    /document_policy                pick a scan policy for document references
    /import source                  import the source's content
    /summarize [n] source           summarize the source's content in n words
    /embedding                      toggle embedding paused or not
    /embed source                   embed the source's content
    /web [n] query                  query web search & return n or 1 results
    /save filename                  store conversation messages
    /load filename                  load conversation messages
    /quit                           to quit
    /help                           to view this help
  EOT
end

def usage
  puts <<~EOT
    Usage: #{File.basename($0)} [OPTIONS]

      -f CONFIG      config file to read
      -u URL         the ollama base url, OLLAMA_URL
      -m MODEL       the ollama model to chat with, OLLAMA_CHAT_MODEL
      -s SYSTEM      the system prompt to use as a file, OLLAMA_CHAT_SYSTEM
      -c CHAT        a saved chat conversation to load
      -C COLLECTION  name of the collection used in this conversation
      -D DOCUMENT    load document and add to embeddings collection (multiple)
      -M             use (empty) MemoryCache for this chat session
      -E             disable embeddings for this chat session
      -V             display the current version number and quit
      -h             this help

  EOT
  exit 0
end

def version
  puts "%s %s" % [ File.basename($0), Ollama::VERSION ]
  exit 0
end

def ollama
  $ollama
end

$opts = go 'f:u:m:s:c:C:D:MEVh'

$ollama_chat_config = OllamaChatConfig.new($opts[?f])
$config             = $ollama_chat_config.config

setup_switches

$opts[?h] and usage
$opts[?V] and version

base_url   = $opts[?u] || $config.url
user_agent = [ File.basename($0), Ollama::VERSION ] * ?/
$ollama    = Client.new(base_url:, debug: $config.debug, user_agent:)

$document_policy = $config.document_policy
$model           = choose_model($opts[?m], $config.model.name)
$model_options   = Options[$config.model.options]
model_system     = pull_model_unless_present($model, $model_options)
messages         = []
$embedding_enabled.set($config.embedding.enabled && !$opts[?E])

if $opts[?c]
  messages.concat load_conversation($opts[?c])
else
  default = $config.system_prompts.default? || model_system
  if $opts[?s] =~ /\A\?/
    change_system_prompt(messages, default, system: $opts[?s])
  else
    system = Utils::FileArgument.get_file_argument($opts[?s], default:)
    system.present? and set_system_prompt(messages, system)
  end
end

if $embedding.on?
  $embedding_model         = $config.embedding.model.name
  $embedding_model_options = Options[$config.embedding.model.options]
  pull_model_unless_present($embedding_model, $embedding_model_options)
  collection = $opts[?C] || $config.embedding.collection
  $documents = Documents.new(
    ollama:,
    model:             $embedding_model,
    model_options:     $config.embedding.model.options,
    database_filename: $config.embedding.database_filename || $ollama_chat_config.database_path,
    collection:        ,
    cache:             configure_cache,
    redis_url:         $config.redis.documents.url?,
    debug:             $config.debug
  )

  document_list = $opts[?D].to_a
  if document_list.any?(&:empty?)
    puts "Clearing collection #{bold{collection}}."
    $documents.clear
    document_list.reject!(&:empty?)
  end
  unless document_list.empty?
    document_list.map! do |doc|
      if doc =~ %r(\Ahttps?://)
        doc
      else
        File.expand_path(doc)
      end
    end
    puts "Collection #{bold{collection}}: Adding #{document_list.size} documents‚Ä¶"
    count = 1
    document_list.each_slice(25) do |docs|
      docs.each do |doc|
        fetch_source(doc) do |doc_io|
          embed_source(doc_io, doc, count:)
        end
        count += 1
      end
    end
  end
else
  $documents = Tins::NULL
end

if redis_expiring_url = $config.redis.expiring.url?
  $cache = Documents::RedisCache.new(
    prefix: 'Expiring-',
    url:    redis_expiring_url,
    ex:     $config.redis.expiring.ex,
  )
end

$current_voice = $config.voice.default

puts "Configuration read from #{$ollama_chat_config.filename.inspect} is:", $config
info
puts "\nType /help to display the chat help."

images = []
loop do
  parse_content = true
  input_prompt = bold { color(172) { message_type(images) + " user" } } + bold { "> " }
  content = Reline.readline(input_prompt, true)&.chomp

  case content
  when %r(^/copy$)
    copy_to_clipboard(messages)
    next
  when %r(^/paste$)
    puts bold { "Paste your content and then press C-d!" }
    content = STDIN.read
  when %r(^/markdown$)
    $markdown.toggle
    next
  when %r(^/stream$)
    $stream.toggle
    next
  when %r(^/location$)
    $location.toggle
    next
  when %r(^/voice(?:\s+(change))?$)
    if $1 == 'change'
      change_voice
    else
      $voice.toggle
    end
    next
  when %r(^/list(?:\s+(\d*))?$)
    last = if $1
             2 * $1.to_i
           end
    list_conversation(messages, last)
    next
  when %r(^/clear$)
    clear_messages(messages)
    puts "Cleared messages."
    next
  when %r(^/clobber$)
    if ask?(prompt: 'Are you sure to clear messages and collection? (y/n) ') =~ /\Ay/i
      clear_messages(messages)
      $documents.clear
      puts "Cleared messages and collection #{bold{$documents.collection}}."
    else
      puts 'Cancelled.'
    end
    next
  when %r(^/pop(?:\s+(\d*))?$)
    if messages.size > 1
      n = $1.to_i.clamp(1, Float::INFINITY)
      r =  messages.pop(2 * n)
      m = r.size / 2
      puts "Popped the last #{m} exchanges."
    else
      puts "No more exchanges you can pop."
    end
    list_conversation(messages, 2)
    next
  when %r(^/model$)
    $model = choose_model('', $model)
    next
  when %r(^/system$)
    change_system_prompt(messages, $system)
    info
    next
  when %r(^/regenerate$)
    if content = messages[-2]&.content
      content.gsub!(/\nConsider these chunks for your answer.*\z/, '')
      messages.pop(2)
    else
      puts "Not enough messages in this conversation."
      redo
    end
    parse_content = false
    content
  when %r(^/collection(?:\s+(clear|change))?$)
    case $1 || 'change'
    when 'clear'
      loop do
        tags = $documents.tags.add('[EXIT]').add('[ALL]')
        tag = Utils::Chooser.choose(tags, prompt: 'Clear? %s')
        case tag
        when nil, '[EXIT]'
          puts "Exiting chooser."
          break
        when '[ALL]'
          if ask?(prompt: 'Are you sure? (y/n) ') =~ /\Ay/i
            $documents.clear
            puts "Cleared collection #{bold{$documents.collection}}."
            break
          else
            puts 'Cancelled.'
            sleep 3
          end
        when /./
          $documents.clear(tags: [ tag ])
          puts "Cleared tag #{tag} from collection #{bold{$documents.collection}}."
          sleep 3
        end
      end
    when 'change'
      choose_collection($documents.collection)
    end
    next
  when %r(^/info$)
    info
    next
  when %r(^/document_policy$)
    choose_document_policy
    next
  when %r(^/import\s+(.+))
    parse_content = false
    content       = import($1) or next
  when %r(^/summarize\s+(?:(\d+)\s+)?(.+))
    parse_content = false
    content       = summarize($2, words: $1) or next
  when %r(^/embedding$)
    $embedding_paused.toggle(show: false)
    $embedding.show
    next
  when %r(^/embed\s+(.+))
    parse_content = false
    content       = embed($1) or next
  when %r(^/web\s+(?:(\d+)\s+)?(.+))
    parse_content   = false
    urls            = search_web($2, $1.to_i)
    urls.each do |url|
      fetch_source(url) { |url_io| embed_source(url_io, url) }
    end
    urls_summarized = urls.map { summarize(_1) }
    query   = $2.inspect
    results = urls.zip(urls_summarized).
      map { |u, s| "%s as \n:%s" % [ u, s ] } * "\n\n"
    content = $config.prompts.web % { query:, results: }
  when %r(^/save\s+(.+)$)
    save_conversation($1, messages)
    puts "Saved conversation to #$1."
    next
  when %r(^/load\s+(.+)$)
    messages = load_conversation($1)
    puts "Loaded conversation from #$1."
    next
  when %r(^/quit$)
    puts "Goodbye."
    exit 0
  when %r(^/)
    display_chat_help
    next
  when ''
    puts "Type /quit to quit."
    next
  when nil
    puts "Goodbye."
    exit 0
  end

  content, tags = if parse_content
                    parse_content(content, images)
                  else
                    [ content, Utils::Tags.new ]
                  end

  if $embedding.on? && content
    records = $documents.find_where(
      content.downcase,
      tags:,
      prompt:     $config.embedding.model.prompt?,
      text_size:  $config.embedding.found_texts_size?,
      text_count: $config.embedding.found_texts_count?,
    )
    unless records.empty?
      content += "\nConsider these chunks for your answer:\n\n"\
        "#{records.map { [ _1.text, _1.tags_set ] * ?\n }.join("\n\n---\n\n")}"
    end
  end

  if location = at_location.full?
    content += " [#{location} ‚Äì do not comment on this the time and location, "\
      "just consider it for eventual queries]"
  end

  messages << Message.new(role: 'user', content:, images: images.dup)
  images.clear
  handler = FollowChat.new(messages:, markdown: $markdown.on?, voice: ($current_voice if $voice.on?))
  ollama.chat(model: $model, messages:, options: $model_options, stream: $stream.on?, &handler)

  if $embedding.on? && !records.empty?
    puts "", records.map { |record|
      link = if record.source =~ %r(\Ahttps?://)
               record.source
             else
               'file://%s' % File.expand_path(record.source)
             end
      [ link, record.tags.first ]
    }.uniq.map { |l, t| hyperlink(l, t) }.join(' ')
    $config.debug and jj messages
  end
rescue Interrupt
  puts "Type /quit to quit."
end
